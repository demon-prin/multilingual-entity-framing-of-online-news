{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQX-1e4Ez0Ow"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install bitsandbytes\n",
        "!pip install accelerate\n",
        "!pip install torch\n",
        "import transformers\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login()"
      ],
      "metadata": {
        "id": "LvXY1PJUz8kF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_id = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
        "\n",
        "pipeline = transformers.pipeline(\n",
        "    \"text-generation\",\n",
        "    model=model_id,\n",
        "    # The quantization line\n",
        "    model_kwargs={\"torch_dtype\": torch.bfloat16, \"load_in_4bit\": True}\n",
        ")"
      ],
      "metadata": {
        "id": "zhqaHKLwz94e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "import torch\n",
        "\n",
        "def GetEntity(frase,entita):\n",
        "\n",
        "  prompt=f\"\"\"\n",
        "        Your task is to generate sentences while leaving the meaning unchanged.\n",
        "        You will be given as input a sentence and the name of an entity, create a new sentence\n",
        "        leaving the given entity and general meaning unchanged.\n",
        "        Do not add comments or explanations. It is not enough to change names of people or places. Try to change words and use synonyms.\n",
        "        Entit√†: {entita}\n",
        "        Frase: {frase}\n",
        "        Nuova Frase:\n",
        "  \"\"\"\n",
        "\n",
        "  messages = [\n",
        "    {\"role\": \"system\", \"content\": \"Answer questions\"},\n",
        "    {\"role\": \"user\", \"content\": f\"{prompt}\"},\n",
        "  ]\n",
        "\n",
        "  prompt = pipeline.tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True\n",
        "  )\n",
        "\n",
        "  terminators = [\n",
        "    pipeline.tokenizer.eos_token_id,\n",
        "    pipeline.tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
        "  ]\n",
        "\n",
        "  outputs = pipeline(\n",
        "    prompt,\n",
        "    max_new_tokens=256,\n",
        "    eos_token_id=terminators,\n",
        "    do_sample=True,\n",
        "    temperature=0.6,\n",
        "    top_p=0.9,\n",
        "  )\n",
        "\n",
        "\n",
        "  classe=(outputs[0][\"generated_text\"][len(prompt):])\n",
        "\n",
        "  return classe\n",
        "\n",
        "GetEntity(\"Hi! My name is Matteo and i love football\",\"Matteo\")"
      ],
      "metadata": {
        "id": "i8VXYu610EYv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "path_annotations=\"train_datasetV12.csv\"\n",
        "df = pd.read_csv(path_annotations, usecols=[\"Frase\", \"Name\", \"Start\", \"End\", \"Role\", \"Descriptor\"])\n",
        "df_protagonist = pd.DataFrame(columns=['frase','entity','sottoclassi'])\n",
        "\n",
        "for index, row in df.iterrows():\n",
        "  sub_classi=row['Descriptor'].split()\n",
        "  entity = row['Name'].lower()\n",
        "  sentence = row['Frase']\n",
        "  descriptor=row['Descriptor']\n",
        "  nuove_righe=[]\n",
        "\n",
        "  if 'foreign' in sub_classi:\n",
        "    sub_classi.remove('foreign')\n",
        "    sub_classi.remove('adversary')\n",
        "    sub_classi.append('Foreign Adversary')\n",
        "\n",
        "  sub_classi = [f\"{pr.capitalize()}\" for pr in sub_classi]\n",
        "\n",
        "  for sb in sub_classi:\n",
        "    new_row = {\n",
        "        'frase': sentence,\n",
        "        'entity': entity,\n",
        "        'sottoclassi':sb,\n",
        "        'Start':row['Start'],\n",
        "        'End':row['End'],\n",
        "        'Role':row['Role']\n",
        "      }\n",
        "    nuove_righe.append(new_row)\n",
        "\n",
        "  temp_df = pd.DataFrame(nuove_righe)\n",
        "\n",
        "  df_protagonist = pd.concat([df_protagonist, temp_df], ignore_index=True)\n",
        "\n",
        "print(len(df_protagonist))\n",
        "df_protagonist.sottoclassi.value_counts()\n"
      ],
      "metadata": {
        "id": "gd0NUEE80MEa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "da_migliorare=['Saboteur','Bigot','Traitor','Scapegoat','Martyr','Forgotten','Spy']\n",
        "for index, row in df_protagonist.iterrows():\n",
        "  entity = row['entity'].lower()\n",
        "  sentence = row['frase']\n",
        "  des=row['sottoclassi']\n",
        "  nuove_righe=[]\n",
        "  if des in da_migliorare:\n",
        "    nuova_frase=GetEntity(sentence,entity)\n",
        "    new_row = {\n",
        "        'Frase': nuova_frase,\n",
        "        'Name': entity,\n",
        "        'Start':row['Start'],\n",
        "        'End':row['End'],\n",
        "        'Role':row['Role'],\n",
        "        'Descriptor':des\n",
        "      }\n",
        "    nuove_righe.append(new_row)\n",
        "\n",
        "\n",
        "  temp_df = pd.DataFrame(nuove_righe)\n",
        "  df = pd.concat([df, temp_df], ignore_index=True)\n"
      ],
      "metadata": {
        "id": "P5DaoNlf0SjD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}